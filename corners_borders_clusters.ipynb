{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Time taken: 34.739901304244995 s ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sobel filters to find image gradients\n",
    "sx, sy = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]]), np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "\n",
    "# A picture\n",
    "img = 'cat.jpg'\n",
    "\n",
    "def load_and_convert(loc):\n",
    "    # Returns image pixel values stored in an ndarray #\n",
    "    img = Image.open(loc)\n",
    "    return np.asarray(img)#[:, :, ::4]\n",
    "\n",
    "def greyscale(img, c_weights=[0.3, 0.59, 0.11]):\n",
    "    # Returns ndarray with weight averaged RGB values #\n",
    "    return np.einsum('abc,c->ab', img, c_weights)\n",
    "\n",
    "def pad(img):\n",
    "    # Turns nxm ndarray to (n+2)x(m+2) by mirroring boundary pixel values #\n",
    "    img = np.c_[img, img[:, -1]]\n",
    "    img = np.r_[img, [img[-1, :]]]\n",
    "    img = np.c_[img[:, 0], img]\n",
    "    return np.r_[[img[0, :]], img]\n",
    "    \n",
    "def pixel_coords(img):\n",
    "    # Extracts coordinates of white pixels #\n",
    "    coords = np.empty((img.shape[0]*img.shape[1],2), dtype=np.int64)\n",
    "    c=0\n",
    "    for y in range(img.shape[0]):\n",
    "        for x in range(img.shape[1]):\n",
    "            if img[y, x] == 255:\n",
    "                coords[c,0]=x\n",
    "                coords[c,1]=y\n",
    "                c+=1\n",
    "    return coords[:c,:]\n",
    "    \n",
    "def main(im, k=0.05, gsig=0.5, prec=10**6, rgb=True, show=True, analyse=True, opt=True, printit=False, K=100):\n",
    "    # Main function #\n",
    "    # Image.fromarray().show() just opens the images (takes a few seconds) \n",
    "    # and analysis part uses the EM algorithm to find the optimal amount and locations of corners\n",
    "    # so set show and analyse to False to check the performance of the Harris algorithm. \n",
    "    img = load_and_convert(im)\n",
    "    if rgb: img = greyscale(img)\n",
    "    imgp = pad(img)\n",
    "    gradx = convolve(imgp, sx, mode='valid') # Image gradients in x and y directions\n",
    "    grady = convolve(imgp, sy, mode='valid')\n",
    "    ix = gaussian_filter(gradx**2, gsig) # Applying Gaussian filters\n",
    "    ixy = gaussian_filter(gradx*grady, gsig)\n",
    "    iy = gaussian_filter(grady**2, gsig)\n",
    "    det_m = ix * iy - ixy ** 2 # Determinant and trace of the structuree tensor\n",
    "    tr_m = ix + iy\n",
    "    r = det_m - k * tr_m ** 2\n",
    "    edges, corners = (r<-prec) * 255, (r>prec) * 255\n",
    "    if analyse: # Trying to find the amount and locations of corners\n",
    "        pc = pixel_coords(edges)\n",
    "        if opt: # Looking for optimal number of clusters\n",
    "            k, BIC = 0, [] # Bayesian Information Criterion == BIC\n",
    "            while k < K:\n",
    "                k += 1\n",
    "                gm = GaussianMixture(n_components=k).fit(pc) # EM algorithm to find the optimal amount of clusters and cluster centers\n",
    "                BIC.append(np.log(gm.bic(pc)))\n",
    "            plt.plot(range(k), BIC)\n",
    "            plt.xlabel('Number of clusters')\n",
    "            plt.ylabel('Log of Bayesian Information Criterion (BIC)')\n",
    "            plt.show()\n",
    "            nc = np.argmin(BIC) + 1 # Picking the amount of clusters that minimize BIC\n",
    "        else: nc = K\n",
    "        gm = GaussianMixture(n_components=nc).fit(pc)\n",
    "        colors = np.random.choice(range(256), size=(nc, 3)) # Random colors for different clusters\n",
    "        clustered_data = gm.predict(pc)\n",
    "        if printit:\n",
    "            print('Number of corners:' + str(len(gm.means_)))\n",
    "            print('Corner coords:')\n",
    "            for i in gm.means_:\n",
    "                print(i.astype(int))\n",
    "        clusters = np.zeros((corners.shape[0], corners.shape[1], 3), dtype='uint8')\n",
    "        for c in range(len(pc)):\n",
    "            clusters[pc[c][1]][pc[c][0]] = colors[clustered_data[c]]\n",
    "    if show:\n",
    "        Image.fromarray(img).show() # Image #1 - the image in grey scale\n",
    "        Image.fromarray(edges).show() # Image #2 - the edges\n",
    "        Image.fromarray(corners).show() # Image #3 - the corners\n",
    "        Image.fromarray(np.array(clusters)).show() # Image #4 - the clustered corners\n",
    "        Image.fromarray(np.array(edges+corners)).show()\n",
    "    #IMG = ImageOps.invert(Image.fromarray(edges).convert('RGB'))\n",
    "    #IMG.show()\n",
    "    return clusters\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    out = main(img, prec=10**6, show=True, gsig=0.5, analyse=True, opt=False, K=20) # Note: analysing the 2Mpx images takes a whiiiiile\n",
    "    print(\"--- Time taken: %s s ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
